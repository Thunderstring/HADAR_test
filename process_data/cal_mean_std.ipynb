{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取mat文件名列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene1/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene2/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene3/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene4/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene5/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene6/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene7/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene8/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene9/HeatCubes/R_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/R_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/L_0001_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/R_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/R_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/R_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/L_0005_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/L_0003_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/L_0002_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/L_0004_heatcube.mat', '/mnt/Disk/zx/HADAR/HADAR_database/Scene10/HeatCubes/R_0005_heatcube.mat']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "matfile = []\n",
    "root = '~/workspace/zx/HADAR_database/'\n",
    "for i in list(range(1,11)):\n",
    "    filename = os.listdir(os.path.join(root, f'Scene{i}', 'HeatCubes'))\n",
    "# print(filename)\n",
    "# print(len(filename))\n",
    "    for file in filename:\n",
    "        if file[-3:] == 'mat':\n",
    "            matfile.append(os.path.join(root, f'Scene{i}', 'HeatCubes') + '/' + file)\n",
    "print(matfile)\n",
    "print(len(matfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算均值(笨方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_data = np.zeros((1080, 1920, 54))\n",
    "squared_sum_data = np.zeros((1080, 1920, 54))\n",
    "\n",
    "# 逐个加载 .mat 文件并累加数据\n",
    "for mat in matfile:\n",
    "    data = scio.loadmat(mat)[\"S\"]\n",
    "    sum_data += data\n",
    "    # squared_sum_data += data ** 2\n",
    "\n",
    "# 计算均值\n",
    "mean_data = sum_data / len(matfile)\n",
    "print(mean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 54)\n",
      "(54,)\n",
      "[0.12748783 0.12627115 0.12497532 0.12335116 0.12193488 0.12066795\n",
      " 0.11935496 0.11785538 0.116255   0.11489087 0.113418   0.11189044\n",
      " 0.11008062 0.10837003 0.10679806 0.10533342 0.10358894 0.10194882\n",
      " 0.10018807 0.09845957 0.0966946  0.09502911 0.09324332 0.09151543\n",
      " 0.0899607  0.08820999 0.08656708 0.08468028 0.08295209 0.08126638\n",
      " 0.07963969 0.07800428 0.07637244 0.07473466 0.07300496 0.07159756\n",
      " 0.06987019 0.06832604 0.06682423 0.06535706 0.06391094 0.06240862\n",
      " 0.06099769 0.05969098 0.05824873 0.05685574 0.05553543 0.05418464\n",
      " 0.05291252 0.05142135 0.05038364 0.04926283 0.04805696 0.04689194]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.mean(mean_data, axis = 0)\n",
    "print(x1.shape)\n",
    "mean_ = np.mean(x1, axis = 0)\n",
    "print(mean_.shape)\n",
    "print(mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算均值和方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据\n",
    "读取后为np.array, dtype = float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1080, 1920, 54)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for mat in matfile:\n",
    "    sub_data = scio.loadmat(mat)[\"S\"]\n",
    "    data.append(sub_data)\n",
    "data = np.array(data)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 循环计算\n",
    "计算缓慢，但占用内存较少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 100, 1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "data_ = np.transpose(data, [3, 0, 1, 2])\n",
    "print(data_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012768574 0.12748851\n",
      "0.012816164 0.12627104\n",
      "0.012860647 0.12497447\n",
      "0.012785383 0.123351745\n",
      "0.01280456 0.12193543\n",
      "0.012723958 0.1206676\n",
      "0.012870256 0.11935494\n",
      "0.013004693 0.11785532\n",
      "0.012732691 0.11625574\n",
      "0.012467056 0.11489139\n",
      "0.012328725 0.11341784\n",
      "0.012257273 0.111889176\n",
      "0.012320152 0.11008014\n",
      "0.012488206 0.108370624\n",
      "0.012293289 0.10679825\n",
      "0.0121145705 0.10533531\n",
      "0.012185608 0.103589214\n",
      "0.012023781 0.10194851\n",
      "0.012024979 0.10018828\n",
      "0.011942158 0.09845957\n",
      "0.011913089 0.09669498\n",
      "0.011736593 0.09502939\n",
      "0.011735512 0.09324287\n",
      "0.011677956 0.09151492\n",
      "0.011484392 0.08996056\n",
      "0.011463704 0.08820983\n",
      "0.011331953 0.086567014\n",
      "0.0114794085 0.08468041\n",
      "0.011431291 0.08295224\n",
      "0.011346702 0.08126643\n",
      "0.011196142 0.07963967\n",
      "0.011058417 0.07800378\n",
      "0.010981622 0.07637229\n",
      "0.010941452 0.074734665\n",
      "0.010783511 0.07300491\n",
      "0.010744004 0.07159753\n",
      "0.010081135 0.06987017\n",
      "0.009869708 0.06832632\n",
      "0.009741623 0.06682408\n",
      "0.00955722 0.06535716\n",
      "0.009384523 0.06391095\n",
      "0.009335937 0.062408622\n",
      "0.009196846 0.060997717\n",
      "0.008956983 0.05969134\n",
      "0.008907695 0.05824868\n",
      "0.008761957 0.056855638\n",
      "0.008625886 0.055535052\n",
      "0.008458811 0.054184694\n",
      "0.008387311 0.052912813\n",
      "0.008644775 0.051421363\n",
      "0.008038243 0.050384395\n",
      "0.008023012 0.049262844\n",
      "0.007895657 0.048057206\n",
      "0.007758511 0.046891488\n",
      "[0.012768575181903842, 0.012816169992913296, 0.01286066717233686, 0.01278539244666665, 0.012804531302369936, 0.012723977000610683, 0.012870245719888604, 0.013004665847292606, 0.012732719490510287, 0.012467062639164169, 0.012328724191312819, 0.012257290092413622, 0.012320165425487513, 0.01248819756098668, 0.01229327978216656, 0.012114586106236955, 0.012185594961042965, 0.01202378061787919, 0.012024986777203006, 0.011942157937918578, 0.011913086222955928, 0.01173661721355335, 0.01173550868384959, 0.01167795182454835, 0.011484393393514203, 0.011463717477443543, 0.011331976296222332, 0.01147940761335593, 0.011431296144185872, 0.011346714915436084, 0.011196151661345827, 0.0110584254450936, 0.010981614282022777, 0.010941432840931162, 0.010783517895734136, 0.010743987689894553, 0.010081127315420843, 0.009869707428326683, 0.009741634743408577, 0.009557235174026308, 0.00938451836674377, 0.009335939851900303, 0.009196842903640206, 0.008956980221665634, 0.008907675643484787, 0.008761963410122838, 0.008625881332555556, 0.00845881692864831, 0.008387308029818538, 0.008644773894132478, 0.008038242544623266, 0.008023002914805387, 0.007895644751791364, 0.007758519133830533] \n",
      "\n",
      "[0.12748782592272317, 0.1262711530983448, 0.12497531814221982, 0.12335116088471294, 0.12193488460440695, 0.12066795291304588, 0.11935495532265415, 0.11785538454018993, 0.11625500280974824, 0.1148908731073877, 0.1134180049005482, 0.11189043849224661, 0.11008061600397398, 0.10837003407982397, 0.10679806481577732, 0.10533342010875543, 0.10358894093721001, 0.10194881779378578, 0.10018807482840839, 0.0984595671136806, 0.09669460260735618, 0.09502911027243108, 0.09324332448233057, 0.09151543287281637, 0.0899606990084236, 0.08820998705334869, 0.08656707719630666, 0.08468028176861045, 0.08295209358562658, 0.08126637656313401, 0.0796396875353875, 0.0780042848067887, 0.07637243883455241, 0.07473465878395019, 0.07300495554953813, 0.07159756054550777, 0.06987019186325279, 0.06832604165693493, 0.06682423031609735, 0.06535705740293603, 0.06391093588579952, 0.06240861978930088, 0.060997687621672216, 0.059690982284663636, 0.05824872748562951, 0.0568557370432917, 0.05553543438832333, 0.054184644077276745, 0.05291252286579506, 0.05142134960466697, 0.05038363856281396, 0.04926282645703098, 0.04805695560561654, 0.04689193702154321]\n"
     ]
    }
   ],
   "source": [
    "mean = []\n",
    "std = []\n",
    "for i in range(data_.shape[0]):\n",
    "    temp = []\n",
    "    for j in range(data_.shape[1]):\n",
    "        for k in range(data_.shape[2]):\n",
    "            for l in range(data_.shape[3]):\n",
    "                temp.append(data_[i][j][k][l])\n",
    "    # sum.append(temp)\n",
    "    std.append(np.std(temp, dtype=np.float64))\n",
    "    mean.append(np.mean(temp, dtype=np.float64))\n",
    "    print(np.std(temp), np.mean(temp))\n",
    "print(std,'\\n')\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy函数计算   \n",
    "计算速度快，但占用内存过多，float64时计算std会爆内存\n",
    "原来是精度问题，float64格式占用太多内存，所以爆了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准差: (54,) \n",
      " [0.05028315 0.05028315 0.04944337 0.04620381 0.03978596 0.03729569\n",
      " 0.0372374  0.03717686 0.03714329 0.03666838 0.03643168 0.03633262\n",
      " 0.03617803 0.03608987 0.03605216 0.03610504 0.03614428 0.03614492\n",
      " 0.03608035 0.03604452 0.03601095 0.03598135 0.03588888 0.03559903\n",
      " 0.03555556 0.03555556 0.03555556 0.03555556 0.03555556 0.03555556\n",
      " 0.03320451 0.02637598 0.02629201 0.02618572 0.02609832 0.02560673\n",
      " 0.02528262 0.02517189 0.02514802 0.02514157 0.02514157 0.02514157\n",
      " 0.02514157 0.02514157 0.02514157 0.02294485 0.01829932 0.01825539\n",
      " 0.01823597 0.01811396 0.01781109 0.01781249 0.01779993 0.01780893]\n"
     ]
    }
   ],
   "source": [
    "# mean = np.mean(data, axis=(0, 1, 2),dtype=np.float64)  # 计算均值，axis指定了要沿着哪些轴计算均值\n",
    "std = np.std(data, axis=(0, 1, 2), dtype=np.float32)    # 计算标准差\n",
    "\n",
    "# print(\"均值\", mean.shape, '\\n', mean)\n",
    "print(\"标准差:\", std.shape, '\\n', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值 (54,) \n",
      " [0.12748783 0.12627115 0.12497532 0.12335116 0.12193488 0.12066795\n",
      " 0.11935496 0.11785538 0.116255   0.11489087 0.113418   0.11189044\n",
      " 0.11008062 0.10837003 0.10679806 0.10533342 0.10358894 0.10194882\n",
      " 0.10018807 0.09845957 0.0966946  0.09502911 0.09324332 0.09151543\n",
      " 0.0899607  0.08820999 0.08656708 0.08468028 0.08295209 0.08126638\n",
      " 0.07963969 0.07800428 0.07637244 0.07473466 0.07300496 0.07159756\n",
      " 0.06987019 0.06832604 0.06682423 0.06535706 0.06391094 0.06240862\n",
      " 0.06099769 0.05969098 0.05824873 0.05685574 0.05553543 0.05418464\n",
      " 0.05291252 0.05142135 0.05038364 0.04926283 0.04805696 0.04689194]\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(data, axis=(0, 1, 2),dtype=np.float128)  # 计算均值，axis指定了要沿着哪些轴计算均值\n",
    "# std = np.std(data, axis=(0, 1, 2), dtype=np.float32)    # 计算标准差\n",
    "\n",
    "print(\"均值\", mean.shape, '\\n', mean)\n",
    "# print(\"标准差:\", std.shape, '\\n', std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 失败案例\n",
    "一个gpu内存不够，西巴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_tensor = torch.tensor(data)\n",
    "\n",
    "# 将数据转移到GPU上\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_gpu = data_tensor.to(device)\n",
    "\n",
    "# 计算最后一个通道维度的标准差\n",
    "std_gpu = torch.std(data_gpu, dim=(0, 1, 2), unbiased=False, keepdim=False)  \n",
    "\n",
    "# 将结果转移到CPU上\n",
    "std = std_gpu.cpu().numpy()\n",
    "\n",
    "print(\"标准差:\", std.shape, '\\n', std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个gpu \n",
    "数学上来说结果不能合并，西巴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设你有一个名为data的四维数组，其形状为(100, 1080, 1920, 54)\n",
    "data_tensor = torch.tensor(data)\n",
    "\n",
    "# 将数据平均分配到两个GPU上\n",
    "device1 = torch.device(\"cuda:0\")  # 第一个GPU\n",
    "device2 = torch.device(\"cuda:1\")  # 第二个GPU\n",
    "\n",
    "data_gpu1 = data_tensor[:50].to(device1)  # 将前50个样本放在第一个GPU上\n",
    "data_gpu2 = data_tensor[50:].to(device2)  # 将后50个样本放在第二个GPU上\n",
    "\n",
    "# 计算每个GPU上最后一个通道维度的标准差\n",
    "# std_gpu1 = torch.std(data_gpu1, dim=(0, 1, 2), dtype=torch.float64)\n",
    "# std_gpu2 = torch.std(data_gpu2, dim=(0, 1, 2), dtype=torch.float64)\n",
    "std_gpu1 = torch.std(data_gpu1, dim=(0, 1, 2), unbiased=False, keepdim=False)\n",
    "std_gpu2 = torch.std(data_gpu2, dim=(0, 1, 2), unbiased=False, keepdim=False)\n",
    "\n",
    "\n",
    "# 合并结果\n",
    "std = torch.cat((std_gpu1.unsqueeze(0), std_gpu2.unsqueeze(0)), dim=0).cpu().numpy()\n",
    "\n",
    "print(\"标准差:\", std.shape, '\\n', std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "texnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
