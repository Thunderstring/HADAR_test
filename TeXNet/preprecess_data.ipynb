{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Jimin, to understand the codes of HADAR\n",
    "\n",
    "Started 2023-08-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljm/anaconda3/envs/texnet/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import os\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '~/workspace/zx/HADAR_database/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The directory names of the downloaded data are renamed to Scene1, Scene2, ..., Scene10.\n",
    "\n",
    "`matName_FullDatabase.mat`: the materials in the dataset, 30 kinds in total. \n",
    "\n",
    "sky asphalt tilePavement cinderblock brick wall marble stone soil al weatheredMetal brass al2o3 oxidizedSteel iron\n",
    "\n",
    "carpaint plasticPaint yellowSpray carwindow crystalGlass tire cloths card tree grass flower water human bark concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sky', 'asphalt', 'tilePavement', 'cinderblock', 'brick', 'wall', 'marble', 'stone', 'soil', 'al', 'weatheredMetal', 'brass', 'al2o3', 'oxidizedSteel', 'iron', 'carpaint', 'plasticPaint', 'yellowSpray', 'carwindow', 'crystalGlass', 'tire', 'cloths', 'card', 'tree', 'grass', 'flower', 'water', 'human', 'bark', 'concrete']\n"
     ]
    }
   ],
   "source": [
    "materialsFile = os.path.join(root, 'matName_FullDatabase.mat')\n",
    "materials = np.squeeze(scio.loadmat(materialsFile)['matName'])\n",
    "materialsName = list()\n",
    "for i in range(materials.shape[0]):\n",
    "    materialsName.append(materials[i][0])\n",
    "print(materialsName)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data of scene 1 to 10. The data of scence 11 are different. \n",
    "\n",
    "`/groundtruth/eMap/eList.mat`: emissivity or index of the materials (not sure) contained in the scence, values in 1-30. It can be seen as the global index of materials.\n",
    "\n",
    "`/groundtruth/eMap/eMap_L(R)_000X.mat`: index of the materials in eList, values in 1-len(eList). It can be seen as the local scene index. \n",
    "\n",
    "eList preprocessing change the local index to global index. The results are save as \n",
    "`/groundtruth/eMap/new_eMap_L(R)_000X.npy`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eMap, material index map, change from Matlab's mat to Numpy's npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eMap preprocessing\n",
      "Processing subfolder Scene1\n",
      "20 materials included:  ['cloths' 'human' 'carwindow' 'crystalGlass' 'carpaint' 'al'\n",
      " 'weatheredMetal' 'tire' 'asphalt' 'tilePavement' 'brass' 'al2o3'\n",
      " 'plasticPaint' 'yellowSpray' 'sky' 'brick' 'oxidizedSteel' 'cinderblock'\n",
      " 'marble' 'iron'] \n",
      "\n",
      "Processing subfolder Scene2\n",
      "20 materials included:  ['cloths' 'human' 'carwindow' 'crystalGlass' 'carpaint' 'al'\n",
      " 'weatheredMetal' 'tire' 'asphalt' 'tilePavement' 'brass' 'al2o3'\n",
      " 'plasticPaint' 'yellowSpray' 'sky' 'brick' 'oxidizedSteel' 'cinderblock'\n",
      " 'marble' 'iron'] \n",
      "\n",
      "Processing subfolder Scene3\n",
      "10 materials included:  ['sky' 'asphalt' 'tilePavement' 'stone' 'grass' 'tree' 'card'\n",
      " 'weatheredMetal' 'carwindow' 'wall'] \n",
      "\n",
      "Processing subfolder Scene4\n",
      "4 materials included:  ['sky' 'soil' 'grass' 'tree'] \n",
      "\n",
      "Processing subfolder Scene5\n",
      "9 materials included:  ['sky' 'asphalt' 'cinderblock' 'soil' 'grass' 'water' 'al' 'carpaint'\n",
      " 'carwindow'] \n",
      "\n",
      "Processing subfolder Scene6\n",
      "7 materials included:  ['sky' 'tree' 'soil' 'stone' 'water' 'flower' 'grass'] \n",
      "\n",
      "Processing subfolder Scene7\n",
      "9 materials included:  ['sky' 'tree' 'soil' 'marble' 'card' 'water' 'grass' 'stone' 'flower'] \n",
      "\n",
      "Processing subfolder Scene8\n",
      "10 materials included:  ['sky' 'wall' 'cloths' 'carpaint' 'al' 'tree' 'carwindow' 'card' 'tire'\n",
      " 'grass'] \n",
      "\n",
      "Processing subfolder Scene9\n",
      "6 materials included:  ['sky' 'stone' 'soil' 'water' 'tree' 'grass'] \n",
      "\n",
      "Processing subfolder Scene10\n",
      "3 materials included:  ['sky' 'stone' 'soil'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "################ eList Processing #######################\n",
    "ids = [f\"L_{i:04d}\" for i in range(1, 6)]\n",
    "ids += [f\"R_{i:04d}\" for i in range(1, 6)]\n",
    "SUBFOLDERS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "SUBFOLDERS = [\"Scene\"+str(_) for _ in SUBFOLDERS]\n",
    "\n",
    "print(\"eMap preprocessing\")\n",
    "for subfolder in SUBFOLDERS:\n",
    "    print(\"Processing subfolder\", subfolder)\n",
    "    elist_file = os.path.join(root, subfolder, 'GroundTruth', 'eMap', f\"eList.mat\")\n",
    "    e_list = np.squeeze(np.asarray(scio.loadmat(elist_file)[\"eList\"]))\n",
    "    print(e_list.shape[0], \"materials included: \", np.array(materialsName)[e_list-1], \"\\n\")\n",
    "\n",
    "    e_files = []\n",
    "    for id in ids:\n",
    "        e_files.append(os.path.join(root, subfolder, 'GroundTruth', 'eMap', f\"eMap_{id}.mat\"))\n",
    "\n",
    "    for i in range(10):\n",
    "        e_data = scio.loadmat(e_files[i])[\"eMap\"]\n",
    "\n",
    "        data = ((e_list[e_data - 1] - 1))\n",
    "        if i<5:\n",
    "            np.save(os.path.join(root, subfolder, \"GroundTruth\", \"eMap\", \"new_eMap_L_000\"+str(i+1)+\".npy\"),\n",
    "                    np.asarray(data))\n",
    "        else:\n",
    "            np.save(os.path.join(root, subfolder, \"GroundTruth\", \"eMap\", \"new_eMap_R_000\"+str(i-4)+\".npy\"),\n",
    "                    np.asarray(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scene11 is monocular and only has 4 frames.\n",
    "\n",
    "The data file name of heatcubes in `\\Scene11\\HeatCubes` should renamed from `heatcube_000X.mat` to `000X_heatcube.mat` to be consistent with other scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subfolder Scene11\n",
      "6 materials included:  ['soil' 'grass' 'bark' 'water' 'sky' 'concrete'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ids = [f\"{i:04d}\" for i in range(1, 5)]\n",
    "# ids += [f\"R_{i:04d}\" for i in range(1, 5)]\n",
    "SUBFOLDERS = [11]\n",
    "SUBFOLDERS = [\"Scene\"+str(_) for _ in SUBFOLDERS]\n",
    "for subfolder in SUBFOLDERS:\n",
    "    print(\"Processing subfolder\", subfolder)\n",
    "    e_files = []\n",
    "    elist_file = os.path.join(root, subfolder, 'GroundTruth', 'eMap', f\"eList.mat\")\n",
    "    e_list = np.squeeze(np.asarray(scio.loadmat(elist_file)[\"eList\"]))\n",
    "    print(e_list.shape[0], \"materials included: \", np.array(materialsName)[e_list-1], \"\\n\")\n",
    "    \n",
    "    for id in ids:\n",
    "        e_files.append(os.path.join(root, subfolder, 'GroundTruth', 'eMap', f\"eMap_{id}.mat\"))\n",
    "\n",
    "    for i in range(4):\n",
    "        e_data = scio.loadmat(e_files[i])[\"eMap\"]\n",
    "\n",
    "        data = ((e_list[e_data - 1]-1))\n",
    "        np.save(os.path.join(root, subfolder, \"GroundTruth\", \"eMap\", \"new_eMap_000\"+str(i+1)+\".npy\"), np.asarray(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### S_EnvObj_000X.npy, mean of the multispectral heatcubes, S_beta\n",
    "\n",
    "For scene 1-10, generate S_EnvObj_L/R_000X.npy from the heatcubes. \n",
    "\n",
    "Heatcube: 1080x1920x54 ---> 1x54x1080x1920 --AvgPooling--> 1x54x2x1. Useless operation, squeezed laterly. \n",
    "\n",
    "For scene 11, loaded from mat. 1x49x2x1. \n",
    "\n",
    "The heatcube is divided into top (cloudy sky) and bottom (ground) halfs and then calculate their mean respectively. \n",
    "\n",
    "See the Equation S48 in Nature paper's SI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### S_beta Processing ###################################################\n",
    "\n",
    "# Separate for Scene 11\n",
    "S_files = [os.path.join(root, \"Scene11\", \"Radiance_EnvObj\", f\"S_EnvObj_{i:04d}.mat\") for i in range(1, 5)]\n",
    "\n",
    "for j in range(4):\n",
    "    data = scio.loadmat(S_files[j])[\"S_EnvObj\"] # 2x49  两个显著环境物，天空和地面，作为S_beta\n",
    "    data = np.transpose(data)[np.newaxis, ..., np.newaxis] # 1x49x2x1\n",
    "    np.save(os.path.join(root, \"Scene11\", \"HeatCubes\", f\"S_EnvObj_{j+1:04d}.npy\"), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_beta preprocessing\n",
      "processing subfolder Scene1\n",
      "processing subfolder Scene2\n",
      "processing subfolder Scene3\n",
      "processing subfolder Scene4\n",
      "processing subfolder Scene5\n",
      "processing subfolder Scene6\n",
      "processing subfolder Scene7\n",
      "processing subfolder Scene8\n",
      "processing subfolder Scene9\n",
      "processing subfolder Scene10\n"
     ]
    }
   ],
   "source": [
    "SUBFOLDERS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "SUBFOLDERS = [\"Scene\"+str(_) for _ in SUBFOLDERS]\n",
    "ids = [f\"L_{i:04d}\" for i in range(1, 6)]\n",
    "ids += [f\"R_{i:04d}\" for i in range(1, 6)]\n",
    "\n",
    "print(\"S_beta preprocessing\")\n",
    "for subfolder in SUBFOLDERS:\n",
    "    S_files = []\n",
    "    print(\"processing subfolder\", subfolder)\n",
    "    for id in ids:\n",
    "        S_files.append(os.path.join(root, subfolder, 'HeatCubes', f\"{id}_heatcube.mat\"))\n",
    "\n",
    "    for j in range(10):\n",
    "        img = torch.tensor(np.asarray(scio.loadmat(S_files[j])[\"S\"]))   # torch.Size([1080, 1920, 54])\n",
    "        img = torch.permute(img, (2, 0, 1))                             # torch.Size([54, 1080, 1920])\n",
    "        img = torch.reshape(img, (1, 54, 1080, 1920))                   # torch.Size([1, 54, 1080, 1920])\n",
    "        [b, c, h, w] = img.shape\n",
    "        quadratic_split = F.avg_pool2d(img, (h//2, w))  # 平均池化，将图像沿着高度方向切割成了两部分，并对每个部分计算了平均值\n",
    "        mean = quadratic_split.numpy()                  # 得到来自天空和地面的两个辐射S_beta，  1x54x2x1\n",
    "\n",
    "        if j < 5:\n",
    "            np.save(os.path.join(root, subfolder, \"HeatCubes\", \"S_EnvObj_L_000\"+str(j+1)+\".npy\"), np.asarray(mean))\n",
    "        else:\n",
    "            np.save(os.path.join(root, subfolder, \"HeatCubes\", \"S_EnvObj_R_000\"+str(j-4)+\".npy\"), np.asarray(mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "texnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
